<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Format Conversion - juan.benet.ai</title>
  <meta name="viewport" content="width=device-width">

  <!-- CSS -->
  <link href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css" rel="stylesheet" />
  <link href="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.min.css" rel="stylesheet" />
  <link rel="stylesheet" href="/css/syntax.css">
  <link href="/css/main.css" media="all" rel="stylesheet" type="text/css" />

  <!-- jQuery for inlined $ -->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js" ></script>

</head>
<body>

<div class="site">

  <div class="content markdown">
  <h2>
  <small><a href="/">Juan Benet</a> /
  <a class="category" href="/data">
  data</a> /</small>
  Format Conversion</h2>
<p class="meta">2014-03-07</p>

<div class="post">
<div class="alert alert-danger">
  <h1>Warning: Work In Progress</h1>
</div>

<p>File conversion is cumbersome and more complex than it needs to be. There is no good reason why we need thousands of different programs that convert from one format to another. I claim it is possible to create a program which <strong>converts to and from <em>all</em> formats without sacrificing performance or flexibility</strong>.<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup></p>

<h2 id="semantics">Semantics</h2>

<p>Before describing such a program, it is important to define our semantic framework. It strikes me that people use the words <code>encoding</code>, <code>format</code>, and <code>schema</code> too loosely. This is perhaps because the words and their semantic boundaries are not precisely defined. Here are ours:</p>

<ul>
<li><p><a href="/data/2014-02-21/data-management-vocabulary/#schema">schema</a>: the structure, or specification of how information represents meaning.</p></li>
<li><p><a href="/data/2014-02-21/data-management-vocabulary/#format">format</a>: &quot;the way in which something is arranged&quot;; a specification for how to <code>encode</code> and <code>decode</code> a message.</p></li>
<li><p><a href="/data/2014-02-21/data-management-vocabulary/#encoding">encoding</a>: the process of converting <em>information</em> into <em>encoded information</em>, according to a <code>format</code>. The inverse of <code>decoding</code>.</p></li>
</ul>

<p>In general, we can say that data is structured according to a <code>schema</code>, and <code>encoded</code> into a <a href="/data/2014-02-21/data-management-vocabulary/#schema-format-compatibility"><code>format</code> compatible with the <code>schema</code></a>.</p>

<h2 id="problem">Problem</h2>

<p>Using these definitions, then, the program should convert any <a href="/data/2014-02-21/data-management-vocabulary/#format-compatibility">compatible format</a> into another.</p>

<p>Conversion tools between two general formats are not complicated to build. The hard part about building a conversion tool for <em>all</em> formats is that most formats are not general. They are <a href="/data/2014-02-21/data-management-vocabulary/#schema-laden"><em>schema-laden</em></a>, and are thus not perfectly compatible. Parsing and generating byte sequences is tedious and error-prone, but not hard. The real problem, I claim, is <em>converting between schemas</em>.</p>

<h2 id="the-graph-of-formats">The Graph of Formats</h2>

<p>Today, most format conversions happen via format-pair-specific tools. Examples: &quot;json to xml&quot;, &quot;png to jpg&quot;, &quot;xsl to csv&quot;. Actually, these examples are not quite right, because most &quot;format conversions&quot; are not between <a href="/data/2014-02-21/data-management-vocabulary/#universal-format">universal  formats</a>, but rather between <a href="/data/2014-02-21/data-management-vocabulary/#schema-laden%7D"><em>schema-laden</em> formats</a>. This means tools that convert from &quot;this custom format expressing geometries&quot; to &quot;GeoJSON&quot;, or between csvs with different column sets, or value ranges. For example:</p>
<div class="highlight"><pre><code class="csv language-csv" data-lang="csv">% cat area-codes.csv
CITY,STATE,AREACODE
SAN DIEGO,CA,619
SAN FRANCISCO,CA,415
SAN JOSE,CA,408

% ./us-city-codes.py area-codes.csv
City,Dial Code
San Diego,+1-619
San Francisco,+1-415
San Jose,+1-408
</code></pre></div>
<p>This transformation is trivial: (a) the <code>STATE</code> column was dropped, (b) the casing changed, (c) the <code>AREACODE</code> column shifted to <code>Dial Code</code>, which includes a <code>+1-</code> for international calling. And yet, a custom program had to be written to parse the source file and generate the target file. Chances are every time this had to be done, someone had to write a program to create that conversion. Consider more complex format conversions, with files with dozens of columns or deeply nested JSON or XML trees, with numerous transformations here and there. So much valuable time is wasted creating these conversion programs. More is wasted by end users -- particularly non-programmers -- struggling to wrangle data to make it &quot;look right&quot;. This is silly.</p>

<p>Consider a graph of formats where directed edges represent conversion programs. Every time one format needs to be converted into another, a program is written and an edge is added. Sometimes people publish those programs and they can be found on the internet. And if we&#39;re lucky, it&#39;s possible a conversion through an intermediate format exists. This is a pretty brittle system though. Often, programs do not exist, only work one-way, are out of date, or are written again and again but never published anywhere.</p>

<!-- format graph -->

<h2 id="hub-with-universal-data-representation">Hub with Universal Data Representation</h2>

<p>Instead of using a graph with converter edges between formats, consider a hub graph, where the center node is a &quot;master&quot; format that can then be translated to any other format. While it is ambitious to build <em>one</em> format to convert between all other formats losslessly, the benefits are significant. Rather than building <code>&lt;num formats&gt;^2</code><sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup> tools to convert to-and-from, we would only need to build <code>&lt;num formats&gt;</code>.</p>

<p>(Figure of hub here)</p>

<p>\begin{scope}[mindmap, concept color=orange, text=white]
  \node [concept] {Informatique}[clockwise from=-5]
    child {node <a href="log">concept</a> {M{\&#39;e}thodes cat{\&#39;e}goriques}}
    child {node <a href="alg">concept</a> {Algorithmique}}
    child {node <a href="cod">concept</a> {Compression &amp; transmission}}
    child {node <a href="img">concept</a> {Tra{^i}tement des images}}
    child {node <a href="opt">concept</a> {Optimisation}}
    child {node <a href="res">concept</a> {R{\&#39;e}seaux}};
\end{scope}</p>

<h3 id="hub-is-well-established">Hub is Well Established</h3>

<p>This is not new. Compilers have worked with a similar model. Compilers like <a href="http://llvm.org">LLVM</a> take high-level languages, parse them into an Internal Representation (IR), and then emit machine code for the relevant platform. This <em>three-phase design</em> is a great way to address the multiplicity of target architectures and source languages.<sup id="fnref3"><a href="#fn3" rel="footnote">3</a></sup> Rather than building <code>&lt;langs&gt; * &lt;archs&gt;</code> compilers, build one compiler with <code>&lt;langs&gt; + &lt;archs&gt;</code> modules.</p>

<p><img src="http://jbenet.static.s3.amazonaws.com/f44a8a0/llvm-three-phase-design.png" alt="llvm-three-phases"></p>

<!-- Figure from [the AOSA book](http://www.aosabook.org/en/llvm.html). -->

<p>This is not even new to conversion. Conversion tools our there already employ this design. Notably, <a href="http://johnmacfarlane.net/pandoc/">Pandoc</a> converts text documents between a range of markup languages. Though the Pandoc homepage displays a <a href="http://johnmacfarlane.net/pandoc/diagram.png">graph with <code>Source * Target</code> edges</a>, it perhaps should display a hub graph; its design uses parsers, an internal representation, and emitters:</p>

<blockquote>
<p>Pandoc has a modular design: it consists of a set of readers, which parse text in a given format and produce a native representation of the document, and a set of writers, which convert this native representation into a target format. Thus, adding an input or output format requires only adding a reader or writer.
<small class="align-right">Pandoc Documentation</small></p>
</blockquote>

<p>These widely used and well-established software systems use the hub model successfully.</p>

<h3 id="hub-design">Hub Design</h3>

<p>To concretely specify the design, the Hub Design calls for:</p>

<ol>
<li>a Universal Data Representation capable of handling <em>any</em> data format (ambitious).</li>
<li>a module per format, which converts to and from the UDR.</li>
<li>a tool that loads and runs format modules, to facilitate conversion.</li>
</ol>

<p>Building such a Universal Data Representation (UDR) is hard; we need a format that can express <em>every other format</em> well and efficiently (in storage and conversion computation). Building the modules themselves -- which do the heavy lifting -- should be an easy and straightforward process. Modules could either ship with the base tool (better for end users, but centralized), or shipped independently (falling back to maintaining an index). Of course, the UDR can be piped in and out of format converters manually, but this would <a href="https://xkcd.com/927/">do little to shift the status quo</a>. The adoption of this tool, and the benefits of this system, depend on:</p>

<ul>
<li>a modular architecture facilitating the building of format modules.</li>
<li>a wide set of interfaces to simplify usage (CLI, static lib, language bindings, web API)</li>
<li>an open-source project and community to build the modules.<sup id="fnref4"><a href="#fn4" rel="footnote">4</a></sup></li>
</ul>

<p>Though the UDR is a non-trivial question, from a software engineering perspective, I claim this design is much easier to realize than others.</p>

<div class="footnotes">
<hr>
<ol>

<li id="fn1">
<p>At present, I offer a framework to think about the problem. In the future, I hope to offer an existence proof.&nbsp;<a href="#fnref1" rev="footnote">&#8617;</a></p>
</li>

<li id="fn2">
<p>Maximum, of course. Many converters would never be built as most format pairs are incompatible.&nbsp;<a href="#fnref2" rev="footnote">&#8617;</a></p>
</li>

<li id="fn3">
<p>This compiler design is brilliant for many reasons. It  addresses many challenges elegantly, including applying optimization at the IR level, and even <a href="http://www.chromium.org/nativeclient/pnacl/introduction-to-portable-native-client">distributing IR code as &quot;portable&quot; code</a> that is compiled on-demand at the target machines.&nbsp;<a href="#fnref3" rev="footnote">&#8617;</a></p>
</li>

<li id="fn4">
<p>It is important to emphasize these points because they are so often overlooked. Many elegant software projects have failed due to the lack of an interested community, a hostile codebase, or a difficult usage pattern.&nbsp;<a href="#fnref4" rev="footnote">&#8617;</a></p>
</li>

</ol>
</div>

</div>

  </div>


 <!-- Footer -->
  <footer>
    <div id="site-map">
      <h5>juan.benet.ai</h5>
      <ul class="links no-bullet">
        <li><a href="/">Home</a></li>
        <li><a href="/about">About</a></li>
      </ul>
    </div>
    <div id="contact-me">
      <h5>Contact</h5>
      <ul class="links no-bullet">
        <li><a href="https://twitter.com/intent/user?screen_name=juanbenet" target="_blank"><i class="icon-twitter"></i> @juanbenet</a></li>
        <li><a href="https://github.com/jbenet" id="new-issue" target="_blank"><i class="icon-github"></i> github.com/jbenet</a></li>
        <li>
        <a href="http://www.google.com/recaptcha/mailhide/d?k=01LaO8uNTV8Ss8kghGlxHXCw==&amp;c=eEwF2u87Cdkgipi5COLbnA=="
        onclick="window.open('http://www.google.com/recaptcha/mailhide/d?k\07501LaO8uNTV8Ss8kghGlxHXCw\75\75\46c\75eEwF2u87Cdkgipi5COLbnA\75\075', '', 'toolbar=0,scrollbars=0,location=0,statusbar=0,menubar=0,resizable=0,width=500,height=300'); return false;"
        title="Reveal this e-mail address"><i class="icon-envelope"></i>
        click-to-reveal@benet.ai</a>
        </li>
      </ul>
    </div>
  </footer>

</div>

<!-- cdnlibs -->
<script src="//cdnjs.cloudflare.com/ajax/libs/underscore.js/1.5.1/underscore-min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.min.css"></script>

<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48626381-1', 'benet.ai');
  ga('send', 'pageview');

</script>

<script type="text/javascript">
$(document).ready(function() {
  // Modify this template to add or change links.
  var links = _.template('\
    <div class="header-links">\
      <a href="#<%= id %>"><i class="icon icon-link"></i></a>\
    </div>\
  ');

  // If your headers dont already have ids, use this slug fn
  var slugize = function(title) {
    return title.toLowerCase()
      .replace(/[^\w ()]+/g,'')
      .replace(/ +/g,'-');
  }

  // Modify the ':header' selector to apply to other elems
  $(':header').each(function(i, h) {

    // Add an id, if it doesn't have one.
    if (!$(h).attr('id')) {
      var id = $(h).text().replace(/[^A-Za-z0-9_]+/g, '-')
      id = id.replace(/^-+|-+$/g, '')
      $(h).attr('id', slugize($(h).text()));
    }

    // Add the link div
    $(h).append($(links({
      id: $(h).attr('id')
    })));
  });
});
</script>

</body>
</html>
